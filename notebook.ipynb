{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddefc9ca-2eea-4f34-a94a-50289a07880d",
   "metadata": {},
   "source": [
    "<h1><b>RECOMENDABLE EJECUTAR EN KERNEL PYTHON 3.12</b>\n",
    "\n",
    "Importes necesarios</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e619c74-4a76-49cd-b717-ee0d69a9fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install --upgrade pip\\n%pip install scikit-learn\\n%pip install pandas\\n%pip install numpy\\n%pip install joblib\\n%pip install tensorflow[and-cuda]\\n%pip install keras\\n%pip install xgboost\\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%pip install --upgrade pip\n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install joblib\n",
    "%pip install tensorflow[and-cuda]\n",
    "%pip install keras\n",
    "%pip install xgboost\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6fccd52-b911-44fe-ae4a-e8507dd847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import keras\n",
    "import joblib\n",
    "import os\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22d563-bd62-4265-a073-bc2745504b05",
   "metadata": {},
   "source": [
    "<h1>Pipeline de limpieza y preparación de datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b3437d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesador = Pipeline([\n",
    "    ('limpiador', Limpiador()),\n",
    "    ('imputador', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('escalador', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d148e48-c3e8-478e-82a2-1943c6e7b7f5",
   "metadata": {},
   "source": [
    "<h1>Ejecutar el pipeline sobre el set de datos y exportar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b28a733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocesador.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"muestra_ataques.csv\", header=None)\n",
    "X = df.iloc[:, 1:-1]\n",
    "X = preprocesador.fit_transform(X)\n",
    "y = df.iloc[:, -1].str.strip(\" '\").replace({'Normal': 0, 'normal': 0, 'Ataque': 1, 'ataque': 1}).fillna(0).to_numpy(dtype=np.float32)\n",
    "joblib.dump(preprocesador, \"preprocesador.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057bb6a1-47b4-4c0b-8bbe-bdf1a80d22f8",
   "metadata": {},
   "source": [
    "<h1>Definir set de entrenamiento del 80% y set de prueba del 20%</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1237d7c2-1543-4ce6-88b1-a2d7fddc3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "modelos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9249a7c",
   "metadata": {},
   "source": [
    "<h1>Función para prueba de modelos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6863eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(nombre, modelo, X_test, y_test, report=True):\n",
    "    inicio = time.time()\n",
    "\n",
    "    if hasattr(modelo, 'n_features_in_') and modelo.n_features_in_ < X_test.shape[1]:\n",
    "        y_hat = (modelo.predict(PCA(n_components=modelo.n_features_in_).fit_transform(X_test))>=0.5).astype(np.float32)\n",
    "    else:\n",
    "        y_hat = (modelo.predict(X_test)>=0.5).astype(np.float32)\n",
    "\n",
    "    ejecucion = time.time() - inicio\n",
    "\n",
    "    if report:\n",
    "        print('\\n' + '-'*30 + f' {nombre} ' + '-'*30)\n",
    "        print('\\nExactitud:', accuracy_score(y_test,y_hat))\n",
    "        print(f'Tiempo promedio de inferencia: {ejecucion*10e3 : .5f} ms')\n",
    "        print('\\nMatriz de confusion:\\n', confusion_matrix(y_test, y_hat))\n",
    "        print('\\nReporte:\\n', classification_report(y_test, y_hat))\n",
    "    return [nombre, modelo, f1_score(y_test, y_hat), ejecucion]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b20a9c-632a-4bb7-8c67-0a1a8e7eec5c",
   "metadata": {},
   "source": [
    "<h1>Búsqueda de hiperparámetros para modelo Logistic Regression con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1e979a3e-a125-4c22-946f-b18b041aa462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "Tiempo de ejecucion:  0.96 minutos\n",
      "\n",
      "------------------------------ lr ------------------------------\n",
      "\n",
      "Exactitud: 0.9977867401141058\n",
      "Tiempo promedio de inferencia:  10.05411 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20060    14]\n",
      " [   31   227]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       0.94      0.88      0.91       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.97      0.94      0.95     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismae\\AppData\\Local\\Python\\pythoncore-3.12-64\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0, 0.1, 0.3, 0.5, 0.8, 1],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "modelo = LogisticRegression(random_state=123)\n",
    "\n",
    "grid_search = GridSearchCV(modelo, parametros, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('lr', grid_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75b2b1-4187-4dfa-911f-d645b24d9309",
   "metadata": {},
   "source": [
    "<h1>Búsqueda aleatoria de hiperparámetros para modelo Decision Tree con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c4fa71e-f7e4-492f-8bb9-44e3c174dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n",
      "Tiempo de ejecucion:  1.89 minutos\n",
      "\n",
      "------------------------------ clf ------------------------------\n",
      "\n",
      "Exactitud: 0.999606531575841\n",
      "Tiempo promedio de inferencia:  29.99067 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20073     1]\n",
      " [    7   251]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       1.00      0.97      0.98       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       1.00      0.99      0.99     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "parametros = {'max_depth': [i for i in range(1,13)]+[None],\n",
    "              'criterion': ['gini','entropy'],\n",
    "              'min_samples_split': [i for i in range(2,9)],\n",
    "              'min_samples_leaf': [i for i in range(1,7)],\n",
    "              'ccp_alpha': [0,0.0001,0.001,0.01,0.1,1],\n",
    "              'class_weight': ['balanced', None]\n",
    "             }\n",
    "\n",
    "random_search = RandomizedSearchCV(modelo, parametros, cv=3, random_state=123, n_iter=2000, scoring='f1', n_jobs=-1, verbose=1)\n",
    "inicio = time.time()\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('clf', random_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186c102-29e9-4c02-9bc0-2fa4627eca97",
   "metadata": {},
   "source": [
    "<h1>Búsqueda aleatoria de hiperparámetros para modelo K Nearest Neighbors con validación cruzada de 3 carpetas sobre el set de entrenamiento usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2bc665ab-4bfb-47dd-aca2-d0efc62256e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Tiempo de ejecucion:  2.54 minutos\n",
      "\n",
      "------------------------------ knn ------------------------------\n",
      "\n",
      "Exactitud: 0.9994097973637616\n",
      "Tiempo promedio de inferencia:  32658.81300 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20070     4]\n",
      " [    8   250]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       0.98      0.97      0.98       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.99      0.98      0.99     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = KNeighborsClassifier()\n",
    "parametros = {'n_neighbors': range(3, 30, 2),\n",
    "              'weights': ['distance', 'uniform'],\n",
    "              'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "             }\n",
    "random_search = RandomizedSearchCV(modelo, parametros, cv=3, scoring='f1', random_state=123, n_iter=20, n_jobs=-1, verbose=1)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "modelos.append(test_model('knn', random_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c564c34-f827-4b2b-acca-2d30ad38b9be",
   "metadata": {},
   "source": [
    "<h1>Búsqueda de hiperparámetros para Support Vector Machine con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8d6b2a2-2f74-4bdb-828f-cd9733a80931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Tiempo de ejecucion:  0.99 minutos\n",
      "\n",
      "------------------------------ svm ------------------------------\n",
      "\n",
      "Exactitud: 0.9989671453865827\n",
      "Tiempo promedio de inferencia:  849.91932 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20067     7]\n",
      " [   14   244]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       0.97      0.95      0.96       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.99      0.97      0.98     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametros = {'coef0': [75,100,125],\n",
    "              'degree': [2,3,4],\n",
    "              'kernel': ['linear','poly','rbf']\n",
    "             }\n",
    "modelo = svm.SVC()\n",
    "grid_search = GridSearchCV(modelo, parametros, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('svm', grid_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af474f82-fcda-469e-9dfd-558362693583",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de modelo de redes neuronales con una capa de entrada, cinco capas ocultas, dropout y una capa de salida con una funcion de activacion sigmoidal con algoritmo de optimización AdamW y funcion de perdida como entropia binaria cruzada</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d2bad633-de5d-41dd-993a-6c9cf3e62430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9939 - f1: 0.0184 - loss: 0.0385\n",
      "Epoch 2/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - f1: 0.0191 - loss: 0.0106\n",
      "Epoch 3/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - f1: 0.0197 - loss: 0.0074\n",
      "Epoch 4/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9984 - f1: 0.0204 - loss: 0.0061\n",
      "Epoch 5/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9986 - f1: 0.0208 - loss: 0.0053\n",
      "Epoch 6/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - f1: 0.0210 - loss: 0.0054\n",
      "Epoch 7/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - f1: 0.0215 - loss: 0.0055\n",
      "Epoch 8/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - f1: 0.0221 - loss: 0.0058\n",
      "Epoch 9/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9987 - f1: 0.0221 - loss: 0.0051\n",
      "Epoch 10/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9987 - f1: 0.0222 - loss: 0.0047\n",
      "Epoch 11/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9987 - f1: 0.0223 - loss: 0.0045\n",
      "Epoch 12/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9985 - f1: 0.0223 - loss: 0.0054\n",
      "Epoch 13/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9988 - f1: 0.0223 - loss: 0.0049\n",
      "Epoch 14/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9988 - f1: 0.0224 - loss: 0.0047\n",
      "Epoch 15/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9987 - f1: 0.0224 - loss: 0.0049  \n",
      "Epoch 16/20\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9986 - f1: 0.0224 - loss: 0.0051\n",
      "Tiempo de ejecucion:  0.60 minutos\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step\n",
      "\n",
      "------------------------------ nn ------------------------------\n",
      "\n",
      "Exactitud: 0.9984261263033641\n",
      "Tiempo promedio de inferencia:  13738.62028 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20064    10]\n",
      " [   22   236]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       0.96      0.91      0.94       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       0.98      0.96      0.97     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_value= 123\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "modelo = keras.models.Sequential()\n",
    "modelo.add(keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "modelo.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "modelo.add(keras.layers.Dropout(0.2))\n",
    "modelo.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "modelo.add(keras.layers.Dropout(0.2))\n",
    "modelo.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "modelo.add(keras.layers.Dropout(0.2))\n",
    "modelo.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "modelo.add(keras.layers.Dropout(0.2))\n",
    "modelo.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "modelo.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.5\n",
    "        )\n",
    "\n",
    "opt = keras.optimizers.AdamW(learning_rate=lr_schedule)\n",
    "\n",
    "modelo.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\n",
    "        keras.metrics.F1Score(name='f1'),\n",
    "        keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "        ])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "modelo.fit(X_train, y_train.reshape(-1, 1), epochs=20,\n",
    "        batch_size=128,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose = 1\n",
    "        )\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('nn', modelo, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d974f4c",
   "metadata": {},
   "source": [
    "<h1>Búsqueda de hiperparámetros para modelo Extreme Gradient Boosting con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f3f455e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "Tiempo de ejecucion:  1.98 minutos\n",
      "\n",
      "------------------------------ xgb ------------------------------\n",
      "\n",
      "Exactitud: 0.9997540822349007\n",
      "Tiempo promedio de inferencia:  99.99514 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20074     0]\n",
      " [    5   253]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       1.00      0.98      0.99       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       1.00      0.99      1.00     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = xgb.XGBClassifier(objective='binary:logistic', seed=123, eval_metric='logloss')\n",
    "\n",
    "parametros = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [i for i in range(3,10,2)],\n",
    "    'subsample': [0.7, 1.0],\n",
    "    'colsample_bytree': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(modelo, parametros, cv=3, scoring='f1', n_jobs=1, verbose=1)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('xgb', grid_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36677905",
   "metadata": {},
   "source": [
    "<h1>Búsqueda aleatoria de hiperparámetros para modelo Random Forest con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3260221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Tiempo de ejecucion:  2.08 minutos\n",
      "\n",
      "------------------------------ rf ------------------------------\n",
      "\n",
      "Exactitud: 0.9997540822349007\n",
      "Tiempo promedio de inferencia:  350.00086 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[20073     1]\n",
      " [    4   254]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     20074\n",
      "         1.0       1.00      0.98      0.99       258\n",
      "\n",
      "    accuracy                           1.00     20332\n",
      "   macro avg       1.00      0.99      1.00     20332\n",
      "weighted avg       1.00      1.00      1.00     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = RandomForestClassifier(random_state=123)\n",
    "\n",
    "parametros = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(modelo, parametros, cv=3, n_iter=100, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('rf', random_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855e575",
   "metadata": {},
   "source": [
    "<h1>Búsqueda de hiperparámetros para modelo Gaussian Naive Bayes con validación cruzada de 3 carpetas usando concurrencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cfb11234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Tiempo de ejecucion:  0.11 minutos\n",
      "\n",
      "------------------------------ gnb ------------------------------\n",
      "\n",
      "Exactitud: 0.980326578792052\n",
      "Tiempo promedio de inferencia:  260.01930 ms\n",
      "\n",
      "Matriz de confusion:\n",
      " [[19678   396]\n",
      " [    4   254]]\n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     20074\n",
      "         1.0       0.39      0.98      0.56       258\n",
      "\n",
      "    accuracy                           0.98     20332\n",
      "   macro avg       0.70      0.98      0.77     20332\n",
      "weighted avg       0.99      0.98      0.98     20332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "modelo = GaussianNB()\n",
    "grid_search = GridSearchCV(modelo, parametros, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Tiempo de ejecucion: {(time.time() - inicio) / 60 : .2f} minutos')\n",
    "\n",
    "modelos.append(test_model('gnb', grid_search.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8cce5-8225-4851-85ce-b5e054cb1086",
   "metadata": {},
   "source": [
    "<h1>Despliegue y entrenamiento extra del mejor modelo según F1 Score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "91e38aec-e966-4ff6-8f87-5fe869eaa0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: rf\n",
      "F1 Score:  0.990\n"
     ]
    }
   ],
   "source": [
    "modelo = sorted(modelos, key=lambda x: x[2])[-1]\n",
    "\n",
    "# Seleccionar por tiempo de inferencia\n",
    "# modelo = sorted(modelos, key=lambda x: x[-1])[0]\n",
    "\n",
    "modelo[1].fit(X_test, y_test)\n",
    "if (modelo[0] == 'ann'):\n",
    "    modelo[1].save(f'modelo_{modelo[0]}.keras')\n",
    "else:\n",
    "    joblib.dump(modelo[1], f'modelo_{modelo[0]}.pkl')\n",
    "print(f'Mejor modelo: {modelo[0]}')\n",
    "print(f'F1 Score: {modelo[2] : .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ddd4b",
   "metadata": {},
   "source": [
    "<h1>Ejemplo de uso sobre nuevos datos, se obtiene \"output.txt\" con los registros clasificados como ataques</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "62038471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "import numpy as np\n",
    "from preprocessing import *\n",
    "\n",
    "try:\n",
    "    modelo = [f for f in os.listdir(os.curdir) if f.startswith('modelo')][0]\n",
    "    modelo = joblib.load(modelo) if modelo.endswith('.pkl') else keras.models.load_model(modelo)\n",
    "    preprocesador = joblib.load('preprocesador.pkl')\n",
    "except Exception as e:\n",
    "    raise RuntimeError('Archivo no encontrado')\n",
    "\n",
    "df2 = pd.read_csv('testing_ataques.csv', header=None)\n",
    "X = preprocesador.transform(df2)\n",
    "if hasattr(modelo, 'n_features_in_') and modelo.n_features_in_ < X.shape[1]:\n",
    "    result = (modelo.predict(PCA(n_components=modelo.n_features_in_).fit_transform(X))>=0.5).astype(np.float32)\n",
    "else:\n",
    "    result = (modelo.predict(X)>=0.5).astype(np.float32)\n",
    "with open('output.txt', mode='w', encoding='utf-8') as f:\n",
    "    f.write(','.join([str(el+1) for el in np.where(result.astype(int) == 1)[0]]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582f8f4",
   "metadata": {},
   "source": [
    "<h1>Al ser un experimento realista no se verifican resultados pero los resultados reales están en el archivo \"ataques.txt\"</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
